Simple document
================
Catherine Mauro
2021-10-20

# Problem 1

First, we should load the **tidyverse** into our code.

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──

    ## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
    ## ✓ tibble  3.1.4     ✓ dplyr   1.0.7
    ## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
    ## ✓ readr   2.0.1     ✓ forcats 0.5.1

    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

Problem 1 deals with **Instacart** data from the *p8105.datasets* code
provided on the website, which we can now upload.

``` r
library(p8105.datasets)
data("instacart")
```

After loading the set, we can observe some details regarding the data:

There are 1384617 rows and 15 columns in **instacart**.

The variables include order\_id, product\_id, add\_to\_cart\_order,
reordered, user\_id, eval\_set, order\_number, order\_dow,
order\_hour\_of\_day, days\_since\_prior\_order, product\_name,
aisle\_id, department\_id, aisle, department. Columns like order,
product, and user id record unique numeric identifiers, while product
name and department record descriptive character observations from the
data.

``` r
instacart %>%
  group_by(department, aisle) %>%
  count(aisle) %>%
  ggplot(aes(x = department, y = n)) + geom_point() + theme(axis.text.x = element_text
  (angle = 90)) +
  labs(
    title = "aisles by department",
    x = "department name",
    y = "Number of aisles",
    caption = "data from p8105.datasets"
  )
```

![](p8105_hw3_cgm2163_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

We can see from this chart that the *produce* and *dairy/eggs*
departments have the most aisles of any other department.

``` r
instacart %>%
  group_by(department) %>%
  count(product_name) %>%
  mutate(product_rank_in_dept = min_rank(desc(n))) %>%
  filter(product_rank_in_dept == 1) %>%
  arrange(department, product_rank_in_dept) %>%
  knitr::kable()
```

| department      | product\_name                                         |     n | product\_rank\_in\_dept |
|:----------------|:------------------------------------------------------|------:|------------------------:|
| alcohol         | Sauvignon Blanc                                       |   295 |                       1 |
| babies          | Baby Food Stage 2 Blueberry Pear & Purple Carrot      |   310 |                       1 |
| bakery          | 100% Whole Wheat Bread                                |  2298 |                       1 |
| beverages       | Sparkling Water Grapefruit                            |  3359 |                       1 |
| breakfast       | Honey Nut Cheerios                                    |  1218 |                       1 |
| bulk            | Dried Mango                                           |   446 |                       1 |
| canned goods    | Organic Black Beans                                   |  1576 |                       1 |
| dairy eggs      | Organic Whole Milk                                    |  4908 |                       1 |
| deli            | Original Hummus                                       |  2858 |                       1 |
| dry goods pasta | Organic Tomato Basil Pasta Sauce                      |   772 |                       1 |
| frozen          | Blueberries                                           |  2323 |                       1 |
| household       | 100% Recycled Paper Towels                            |  1183 |                       1 |
| international   | Taco Seasoning                                        |   405 |                       1 |
| meat seafood    | Boneless Skinless Chicken Breasts                     |  2088 |                       1 |
| missing         | Organic Riced Cauliflower                             |   823 |                       1 |
| other           | Roasted Almond Butter                                 |   174 |                       1 |
| pantry          | Extra Virgin Olive Oil                                |  2068 |                       1 |
| personal care   | Cotton Swabs                                          |   258 |                       1 |
| personal care   | Lavender Hand Soap                                    |   258 |                       1 |
| pets            | Double Duty Advanced Odor Control Clumping Cat Litter |    84 |                       1 |
| produce         | Banana                                                | 18726 |                       1 |
| snacks          | Lightly Salted Baked Snap Pea Crisps                  |   991 |                       1 |

We can also see from this the top products in each department.

Next, we can write some code to find more about our **instacart** data.

``` r
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

    ## # A tibble: 134 × 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

There are 134 aisles. The aisles with the most items include *fresh
vegetables*, *fresh fruits*, *packaged vegetables fruits*, *yoghurt*,
and *packaged cheese*, all which have more than **41,000** observations.

Next, we can make a plot to show the number of items ordered in each
aisle for those aisles with more than **10,000** observations.

``` r
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
    mutate(
      is.factor(aisle),
      fct_reorder(aisle, n, desc)
    ) %>%
  ggplot(aes(x = aisle, y = n)) + geom_point() + theme(axis.text.x = element_text
  (angle = 90, hjust = 1, vjust = 3)) +
  labs(
    title = "Aisle Plot",
    x = "Aisle Name",
    y = "Number of Items Ordered",
    caption = "data from p8105.datasets"
  )
```

![](p8105_hw3_cgm2163_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

After arranging a graph for all of the aisles with over 10000 items
ordered, we can see that *fresh fruits* and *fresh vegetables* are the
aisles with clearly the most items ordered.

We can make a table further exploring popular items for *baking
ingredients*, *dog food care*, *packaged vegetables fruits*.

``` r
instacart %>%
  group_by(aisle) %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  count(product_name) %>%
  mutate(product_rank_in_aisle = min_rank(desc(n))) %>%
  filter(product_rank_in_aisle <= 3) %>%
  arrange(aisle, product_rank_in_aisle) %>%
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | product\_rank\_in\_aisle |
|:---------------------------|:----------------------------------------------|-----:|-------------------------:|
| baking ingredients         | Light Brown Sugar                             |  499 |                        1 |
| baking ingredients         | Pure Baking Soda                              |  387 |                        2 |
| baking ingredients         | Cane Sugar                                    |  336 |                        3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |                        1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |                        2 |
| dog food care              | Small Dog Biscuits                            |   26 |                        3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |                        1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |                        2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |                        3 |

For **baking ingredients**, the three most common products ordered are
*light brown sugar, pure baking soda, and cane sugar*. For **dog food
care**, the three most common products ordered are *snack sticks,
organix chicken, and small dog biscuits*. Finally, for **packaged
vegetables fruits**, the three most common products ordered are *organic
baby spinach, organic raspberries, and organic blueberries.*

We can also create a 2x7 table tracking the mean hour of day at which
certain apples and ice creams are ordered each day of the week.

``` r
instacart %>%
  group_by(product_name, order_dow) %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  summarize(mean_hod = round(mean(order_hour_of_day), 2)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hod
  ) %>%
knitr::kable()
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

| product\_name    |     0 |     1 |     2 |     3 |     4 |     5 |     6 |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

We can see that, in this case, ice cream is bought earlier in the day
when it is later in the week, while apples vary day to day but are
generally bought earlier in the day than ice cream.

# Problem 2

Problem 2 deals with BRFSS data that

First, we can upload our **BRFSS** data using the *p8105.datasets* code
provided on the website.

``` r
library(p8105.datasets)
data("brfss_smart2010")
```

Next, we should do some data cleaning to ensure that the data have
appropriate variable names,focus on the topic at hand, include only
excellent to poor responses, and organize the responses as a factor
taking levels ordered from poor to excellent

``` r
brfss = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health", response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) %>%
  mutate(
    response = factor(response, ordered = TRUE, levels = c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

After loading the set, we can observe some details regarding the data:

There are 10625 rows and 23 columns in **brfss**.

Now, we can find some answers in our data set:

``` r
locations_2002 = brfss %>%
  filter(year == 2002) %>%
  group_by(locationabbr) %>%
  summarize(
    number_of_locations = n_distinct(locationdesc)
  ) %>%
  filter(number_of_locations > 6)

view(locations_2002)
```

There were 6 states that had 7 or more observations in 2002. They
included CT, FL, MA, NC, NJ, PA

``` r
locations_2010 = brfss %>%
  filter(year == 2010) %>%
  group_by(locationabbr) %>%
  summarize(
    number_of_locations = n_distinct(locationdesc)
  ) %>%
  filter(number_of_locations > 6)
```

There were 14 states that had 7 or more observations in 2010. They
included CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA

Now, we can limit our analysis to just those who responded “Excellent”,
averaging data\_value across state locations.

``` r
excellent_brfss = brfss %>%
  filter(response == "Excellent") %>%
  group_by(year, locationabbr) %>%
  summarize(mean_state_data = mean(data_value, na.rm = TRUE))
```

    ## `summarise()` has grouped output by 'year'. You can override using the `.groups` argument.

Now, we can create a *spaghetti plot* using our new **excellent\_brfss**
dataset.

``` r
ggplot(data = excellent_brfss, aes(x = year, y = mean_state_data, color = locationabbr, group = locationabbr)) + geom_line()
```

![](p8105_hw3_cgm2163_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

This spaghetti plot shows the mean data values from each state over the
years measured in the study.

We can also create a two-panel plot comparing 2006 and 2010 assessing
distribution of *data\_value* across response types in **NYS**.

``` r
ggplot(subset(brfss, year %in% c(2006, 2010, locationabbr == "NY")), aes(x = response, y = data_value, fill = response)) + geom_bar(stat = "identity", position = "dodge") + facet_grid(. ~ year) + theme(axis.text.x = element_text
  (angle = 90)) + labs(
    title = "2006 vs. 2010 plots",
    x = "response type",
    y = "data_value",
    caption = "data from p8105.datasets"
  )
```

    ## Warning: Removed 9 rows containing missing values (geom_bar).

![](p8105_hw3_cgm2163_files/figure-gfm/unnamed-chunk-15-1.png)<!-- -->

We can now see that the distributions of *data\_value* among *response*
in both **2006** and **2010** are quite similar, with “very good” having
the highest bar in both years.

# Problem 3

Problem 3 deals with accelerometer data from the **accel\_data.csv**,
which we can clean, wrangle, and tidy.

``` r
accel =
  read.csv("./accel_data.csv") %>%
  rename(day_num = day_id) %>%
  janitor::clean_names() %>%
  mutate(
     week_section = ifelse(day == "Saturday" | day == "Sunday", "weekend", no = "weekday")) %>%
   mutate(
    day = factor(day, ordered = TRUE, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))
```

However, we can make this look even better by using a *pivot\_longer*
function.

``` r
accel_long = accel %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    values_to = "activity_count") %>%
  mutate(
    minute = factor(minute)
  )
```

The **accel\_long** set contains data from the accelerometer of a 65
year old man collected over 35 days (5 weeks). There are 50400 rows and
6 columns in **accel\_long**. Column names include week, day\_num, day,
week\_section, minute, activity\_count.

``` r
accel_data_sum = accel_long %>%
  group_by(day_num, day, week_section) %>%
  summarize(
    daily_activity_total = sum(activity_count)) 
```

    ## `summarise()` has grouped output by 'day_num', 'day'. You can override using the `.groups` argument.

``` r
knitr::kable(accel_data_sum)
```

| day\_num | day       | week\_section | daily\_activity\_total |
|---------:|:----------|:--------------|-----------------------:|
|        1 | Friday    | weekday       |              480542.62 |
|        2 | Monday    | weekday       |               78828.07 |
|        3 | Saturday  | weekend       |              376254.00 |
|        4 | Sunday    | weekend       |              631105.00 |
|        5 | Thursday  | weekday       |              355923.64 |
|        6 | Tuesday   | weekday       |              307094.24 |
|        7 | Wednesday | weekday       |              340115.01 |
|        8 | Friday    | weekday       |              568839.00 |
|        9 | Monday    | weekday       |              295431.00 |
|       10 | Saturday  | weekend       |              607175.00 |
|       11 | Sunday    | weekend       |              422018.00 |
|       12 | Thursday  | weekday       |              474048.00 |
|       13 | Tuesday   | weekday       |              423245.00 |
|       14 | Wednesday | weekday       |              440962.00 |
|       15 | Friday    | weekday       |              467420.00 |
|       16 | Monday    | weekday       |              685910.00 |
|       17 | Saturday  | weekend       |              382928.00 |
|       18 | Sunday    | weekend       |              467052.00 |
|       19 | Thursday  | weekday       |              371230.00 |
|       20 | Tuesday   | weekday       |              381507.00 |
|       21 | Wednesday | weekday       |              468869.00 |
|       22 | Friday    | weekday       |              154049.00 |
|       23 | Monday    | weekday       |              409450.00 |
|       24 | Saturday  | weekend       |                1440.00 |
|       25 | Sunday    | weekend       |              260617.00 |
|       26 | Thursday  | weekday       |              340291.00 |
|       27 | Tuesday   | weekday       |              319568.00 |
|       28 | Wednesday | weekday       |              434460.00 |
|       29 | Friday    | weekday       |              620860.00 |
|       30 | Monday    | weekday       |              389080.00 |
|       31 | Saturday  | weekend       |                1440.00 |
|       32 | Sunday    | weekend       |              138421.00 |
|       33 | Thursday  | weekday       |              549658.00 |
|       34 | Tuesday   | weekday       |              367824.00 |
|       35 | Wednesday | weekday       |              445366.00 |

Just from our table output, it seems like our patient is much more
active on certain days, but we can create a chart to observe this.

``` r
accel_data_sum %>%
  group_by(day) %>%
  ggplot(aes(x = day, y = daily_activity_total, fill = day)) + geom_bar(stat = "identity", position = "dodge") + labs(
    title = "daily activity graph",
    x = "day of the week",
    y = "daily accelerometer activity",
    caption = "data from p8105.datasets"
  )
```

![](p8105_hw3_cgm2163_files/figure-gfm/unnamed-chunk-19-1.png)<!-- -->

From our bar graph, we can tell that the patient’s most active days are
Sunday and Monday, followed by a sharp drop off in the following few
days, before returning to high activity by the start of the weekend.

``` r
accel_long %>%
  group_by(day_num) %>%
  ggplot(aes(x = minute, y = activity_count, color = day)) + geom_line(aes(color = day)) + geom_smooth(se = FALSE)
```

    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

![](p8105_hw3_cgm2163_files/figure-gfm/unnamed-chunk-20-1.png)<!-- -->

There are no really observable trends, but it appears that Saturday,
Sunday, and Monday are still the days with the highest amounts of
activity per day.

**End of HW3**
